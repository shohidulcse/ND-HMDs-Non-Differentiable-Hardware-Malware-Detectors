{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [8000, 8000, 8000, 8000, 8000, 8000]\n",
      "4 [13000, 13000, 13000, 13000]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    " \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import joblib #save and load model\n",
    " \n",
    "train_size = 0.6\n",
    "validation_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing (df):\n",
    "\n",
    "    #drop 1st row (column title) \n",
    "    for row in range(1):\n",
    "        df = df.drop(row)\n",
    "\n",
    "    #replace NaN = 0 \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    #The pd.to_numberic function will convert all non-parsable strings to 'NaN' \n",
    "    #and the fillna replaces those values with 0\n",
    "    df = df.apply(lambda x: pd.to_numeric(x, errors='coerce')).fillna(0)\n",
    "    df = df.astype(int)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def find_reduced_prediction(y_pred_full, test_df_list):\n",
    "\n",
    "    y_pred_reduced = []\n",
    "\n",
    "    for df_id in range(len(test_df_list)):\n",
    "        start = 0\n",
    "        for i in range(df_id):\n",
    "            start += len(test_df_list[i]) \n",
    "\n",
    "        end = start + len(test_df_list[df_id])\n",
    "        step_size = 1\n",
    "        temp_run_array = y_pred_full[start:end:step_size]\n",
    "\n",
    "        zeros = list(temp_run_array).count(0)\n",
    "        ones = list(temp_run_array).count(1)\n",
    "\n",
    "        if ones > zeros:\n",
    "            y_pred_reduced.append(1)\n",
    "        else:\n",
    "            y_pred_reduced.append(0)\n",
    "\n",
    "    y_pred_reduced = np.array(y_pred_reduced)\n",
    "\n",
    "    return y_pred_reduced \n",
    "\n",
    "\n",
    "\n",
    "def find_misclassification(y_actual, y_predicted, benign, virus):\n",
    "    \n",
    "    misclassified_prog = []\n",
    "    \n",
    "    y_actual = y_test_reduced\n",
    "    y_predicted = y_pred_reduced\n",
    "    for i in range(len(y_actual)):\n",
    "        if y_actual[i] == y_predicted[i]:\n",
    "            print('---')\n",
    "        else:\n",
    "            if y_actual[i] == 0:\n",
    "                print(f'Program {benign[i]}: actual label {y_actual[i]}, predicted as {y_predicted[i]}')\n",
    "            else:\n",
    "                \n",
    "                print(f'Virus Program {virus[i - len(benign)]}: actual label {y_actual[i]}, predicted as {y_predicted[i]}')\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_positive_features(weight):\n",
    "    \n",
    "    positive_weight = []\n",
    "    negative_weight = []\n",
    "    negative_weight_id = []\n",
    "\n",
    "    #argsort gives original index of sorted elements\n",
    "    ascend_id = np.argsort(weight) \n",
    "\n",
    "    descend_id = ascend_id[::-1]\n",
    "\n",
    "    positive_feature_id = list()\n",
    "    count_positive = 0\n",
    "    count_negative = 0\n",
    "    for i in descend_id:\n",
    "        if np.around(weight[i], 6) > 0:\n",
    "            count_positive += 1\n",
    "            positive_feature_id.append(i)\n",
    "            positive_weight.append(round(weight[i], 3))\n",
    "        else:\n",
    "            count_negative += 1\n",
    "            negative_weight.append(round(weight[i], 3))\n",
    "            negative_weight_id.append(i)\n",
    "    return positive_feature_id, positive_weight, negative_weight_id, negative_weight \n",
    "\n",
    "\n",
    "\n",
    "def find_feature_meaning(events, feature_id):\n",
    "    df_preset = pd.read_csv('presets.txt', delimiter=\",\", header=None, low_memory=False)\n",
    "    preset = []\n",
    "    preset__meaning = []\n",
    "    selected_meaning = []\n",
    "\n",
    "    for i in range(0, len(df_preset), 2):\n",
    "        preset.append(df_preset[0][i])\n",
    "\n",
    "    for i in range(1, len(df_preset), 2):\n",
    "        preset__meaning.append(df_preset[0][i])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(feature_id)):\n",
    "        e = events[feature_id[i]]\n",
    "        if e in preset:  \n",
    "            selected_meaning.append(preset__meaning[preset.index(e)])\n",
    "        else:\n",
    "            selected_meaning.append('---')\n",
    "    \n",
    "    return selected_meaning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mibench6 = [1, 2, 3, 4, 5, 6]\n",
    "phoronix7 = [7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "benign = mibench6 \n",
    "\n",
    "# virus = [14, 15, 16, 17, 18, 19]\n",
    "# virus_names = ['spectre1', 'spectre2', 'flush_flush', 'meltdown', 'zombieload', 'rowhammer']\n",
    "\n",
    "virus = [14, 15, 17, 18]\n",
    "virus_names = ['spectre1', 'spectre2', 'meltdown', 'zombieload']\n",
    "\n",
    "train_df_list = []\n",
    "validation_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "\n",
    "train_benign_count = 0\n",
    "validation_benign_count = 0\n",
    "test_benign_count = 0\n",
    "\n",
    "train_malware_count = 0\n",
    "validation_malware_count = 0\n",
    "test_malware_count = 0\n",
    "\n",
    "\n",
    "program_len_list = []\n",
    "for i in benign:\n",
    "    path = f'dataset/Perf_collection/Base_Model_Training_Files/benign/program{i}.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events = list(df.iloc[0, :])\n",
    "    df = preprocessing (df)\n",
    "    \n",
    "    temp_df_list = []\n",
    "    for j in range(4):\n",
    "        temp_df_list.append(df)\n",
    "        \n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp = pd.concat(temp_df_list, ignore_index=True)\n",
    "    \n",
    "    program_len_list.append(len(df_temp))\n",
    "\n",
    "    #df(frac=1) will randomly select rows;\n",
    "    # df_train, df_validate, df_test = np.split(df(frac=1), [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "    #without shuffle\n",
    "#     df_train, df_validate, df_test = np.split(df_temp, [int(train_size*len(df_temp)), int((train_size + validation_size)*len(df_temp))])\n",
    "\n",
    "    train_benign_count += len(df_temp)\n",
    "    validation_benign_count += len(df_temp)\n",
    "    test_benign_count += len(df_temp)\n",
    "\n",
    "    train_df_list.append(df_temp)\n",
    "    validation_df_list.append(df_temp)\n",
    "    test_df_list.append(df_temp)\n",
    "        \n",
    "virus_len_list = []\n",
    "for i in virus:\n",
    "    path = f'dataset/Perf_collection/Base_Model_Training_Files/virus/program{i}.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events = list(df.iloc[0, :])\n",
    "    df = preprocessing (df)\n",
    "    virus_len_list.append(len(df))\n",
    "\n",
    "    #df.sample(frac=1) will randomly select rows;\n",
    "    # df_train, df_validate, df_test = np.split(df(frac=1), [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "    #without shuffle\n",
    "#     df_train, df_validate, df_test = np.split(df, [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "\n",
    "    train_malware_count += len(df)\n",
    "    validation_malware_count += len(df)\n",
    "    test_malware_count += len(df)\n",
    "\n",
    "    train_df_list.append(df)\n",
    "    validation_df_list.append(df)\n",
    "    test_df_list.append(df)\n",
    "\n",
    "    \n",
    "    \n",
    "df_train = pd.DataFrame()\n",
    "df_validation = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "df_train = pd.concat(train_df_list, ignore_index=True)\n",
    "df_validation = pd.concat(validation_df_list, ignore_index=True)\n",
    "df_test = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "#generate labels\n",
    "b = [0 if i < train_benign_count else 1 for i in range( train_benign_count + train_malware_count )]\n",
    "y_train = np.array(b)\n",
    "\n",
    "y_train_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_train_reduced.append(1)\n",
    "y_train_reduced = np.array(y_train_reduced)\n",
    "\n",
    "\n",
    "b = [0 if i < validation_benign_count else 1 for i in range( validation_benign_count + validation_malware_count )]\n",
    "y_validation = np.array(b)\n",
    "\n",
    "\n",
    "y_validation_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_validation_reduced.append(1)\n",
    "y_validation_reduced = np.array(y_validation_reduced)\n",
    "\n",
    "\n",
    "b = [0 if i < test_benign_count else 1 for i in range( test_benign_count + test_malware_count )]\n",
    "y_test = np.array(b)\n",
    "\n",
    "y_test_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_test_reduced.append(1)\n",
    "y_test_reduced = np.array(y_test_reduced)\n",
    "\n",
    "print(len(program_len_list), program_len_list)\n",
    "print(len(virus_len_list), virus_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train  Decision Tree, Random Forest, and Gradient Boosting with 8 features\n",
    "\n",
    "acc_prow = []\n",
    "acc_pprog = []\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "n_feature = len(used_features)\n",
    "\n",
    "df_train_cp = df_train[used_features]\n",
    "df_validation_cp = df_validation[used_features]\n",
    "df_test_cp = df_test[used_features]\n",
    "\n",
    "print(f'{len(used_features)} features:', used_features)\n",
    "\n",
    "DT_8 = tree.DecisionTreeClassifier()\n",
    "DT_8.fit(df_train_cp, y_train)\n",
    "joblib.dump(DT_8, \"model/DT_8.pkl\")\n",
    "\n",
    "RF_8 = RandomForestClassifier()\n",
    "RF_8.fit(df_train_cp, y_train)\n",
    "joblib.dump(RF_8, \"model/RF_8.pkl\")\n",
    "\n",
    "GB_8 = GradientBoostingClassifier()\n",
    "GB_8.fit(df_train_cp, y_train)\n",
    "joblib.dump(GB_8, \"model/GB_8.pkl\")\n",
    "\n",
    "y_pred = DT_8.predict(df_test_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "print(f'\\nDT per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "acc_pprog.append(accuracy)\n",
    "print(f'DT per prog : {accuracy}\\n')\n",
    "find_misclassification(y_test_reduced, y_pred_reduced, benign, virus)\n",
    "\n",
    "y_pred = RF_8.predict(df_test_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "print(f'\\nRF per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "acc_pprog.append(accuracy)\n",
    "print(f'RF per prog : {accuracy}\\n')\n",
    "find_misclassification(y_test_reduced, y_pred_reduced, benign, virus)\n",
    "\n",
    "y_pred = GB_8.predict(df_test_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "print(f'\\nGB per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "acc_pprog.append(accuracy)\n",
    "print(f'GB per prog : {accuracy}\\n')\n",
    "find_misclassification(y_test_reduced, y_pred_reduced, benign, virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shohidul/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extra Tree per row : 1.0\n",
      "Extra Tree per prog : 1.0\n",
      "\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "n_feature = len(used_features)\n",
    "\n",
    "df_train_cp = df_train[used_features]\n",
    "df_validation_cp = df_validation[used_features]\n",
    "df_test_cp = df_test[used_features]\n",
    "\n",
    "ExT_8 = ExtraTreesClassifier()\n",
    "ExT_8.fit(df_train_cp, y_train)\n",
    "joblib.dump(ExT_8, \"model/ExT_8.pkl\")\n",
    "\n",
    "y_pred = ExT_8.predict(df_test_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "print(f'\\nExtra Tree per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "print(f'Extra Tree per prog : {accuracy}\\n')\n",
    "find_misclassification(y_test_reduced, y_pred_reduced, benign, virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature = 1\n",
      "[0.76, 0.91, 0.91, 0.9, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86]\n",
      "feature = 0\n",
      "[0.76, 0.91, 0.91, 0.91, 0.95, 0.97, 0.53, 0.51, 0.51, 0.51]\n",
      "feature = 6\n",
      "[0.76, 0.91, 0.91, 0.91, 0.91, 0.91, 0.86, 0.08, 0.08, 0.08]\n",
      "feature = 18\n",
      "[0.76, 0.91, 0.83, 0.74, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77]\n",
      "feature = 21\n",
      "[0.76, 0.91, 0.91, 0.91, 0.91, 0.81, 0.22, 0.22, 0.22, 0.22]\n",
      "feature = 17\n",
      "[0.76, 0.91, 0.91, 0.92, 0.93, 0.94, 0.23, 0.23, 0.23, 0.23]\n",
      "feature = 2\n",
      "[0.76, 0.91, 0.9, 0.89, 0.87, 0.97, 0.96, 0.96, 0.96, 0.96]\n",
      "feature = 8\n",
      "[0.76, 0.91, 0.91, 0.91, 0.52, 0.55, 0.55, 0.55, 0.55, 0.55]\n"
     ]
    }
   ],
   "source": [
    "# confidence testing\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "\n",
    "increments = [10**i for i in range(1, 10)]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "for feature in range (len(used_features)):\n",
    "\n",
    "    confidence = [0.76]\n",
    "    \n",
    "    for inc in increments:\n",
    "\n",
    "        test_row = list(df_test_cp.loc[len(df_test_cp)-1])\n",
    "        test_row[feature] = test_row[feature] + inc\n",
    "        test_row = np.array(test_row)\n",
    "        test_row = test_row.reshape(1, -1)\n",
    "        conf = ExT_8.predict_proba(test_row)\n",
    "        conf = round(conf[0][1], 2)\n",
    "        confidence.append(conf)\n",
    "    print(f'feature = {used_features[feature]}')\n",
    "    print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'); \n",
      "acc = 1.0\n",
      "accuracy: 1.0 \n",
      "sens 1.0 \n",
      "spec: 1.0\n",
      "precision: 1.0 \n",
      "f1: 1.0\n",
      "\n",
      "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False); \n",
      "acc = 1.0\n",
      "accuracy: 1.0 \n",
      "sens 1.0 \n",
      "spec: 1.0\n",
      "precision: 1.0 \n",
      "f1: 1.0\n",
      "\n",
      "model = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False); \n",
      "acc = 1.0\n",
      "accuracy: 1.0 \n",
      "sens 1.0 \n",
      "spec: 1.0\n",
      "precision: 1.0 \n",
      "f1: 1.0\n",
      "\n",
      "model = ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False); \n",
      "acc = 1.0\n",
      "accuracy: 1.0 \n",
      "sens 1.0 \n",
      "spec: 1.0\n",
      "precision: 1.0 \n",
      "f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Other Performance metrics calcualtion\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "models = [DT_8, RF_8, GB_8, ExT_8]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "df_test_cp = df_test[used_features]\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    y_pred = model.predict(df_test_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_reduced, y_pred_reduced)\n",
    "    accuracy = round(accuracy, 2)\n",
    "\n",
    "    cm = confusion_matrix(y_test_reduced, y_pred_reduced)\n",
    "    tn = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]   \n",
    "    tp = cm[1][1]\n",
    "\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    sens = (tp) / (tp + fn)\n",
    "    spec = (tn) / (tn + fp)\n",
    "    precision = (tp) / (tp + fp)\n",
    "    recall = (tp) / (tp + fn)\n",
    "\n",
    "    sens = round(sens, 2)\n",
    "    spec = round(spec, 2)\n",
    "    precision = round(precision, 2)\n",
    "\n",
    "    f1 = f1_score(y_test_reduced, y_pred_reduced, average='weighted')\n",
    "    f1 = round(f1, 2)\n",
    "    \n",
    "    print(f'\\nmodel = {model}; \\nacc = {acc}')\n",
    "    print('accuracy:', accuracy, '\\nsens', sens, '\\nspec:', spec)\n",
    "    print('precision:', precision, '\\nf1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 504, 1208, 629]\n",
      "\n",
      "DT per row : 0.89\n",
      "DT per prog : 1.0\n",
      "\n",
      "RF per row : 0.93\n",
      "RF per prog : 1.0\n",
      "\n",
      "GB per row : 0.93\n",
      "GB per prog : 1.0\n",
      "\n",
      "Extra Tree per row : 0.93\n",
      "Extra Tree per prog : 1.0\n"
     ]
    }
   ],
   "source": [
    "# ACTUAL FORK attack\n",
    "\n",
    "\n",
    "evasive_virus = [1, 2, 5, 6]\n",
    "\n",
    "eva_len_list = []\n",
    "eva_df_list = []\n",
    "\n",
    "for i in evasive_virus:\n",
    "        \n",
    "    path = f'dataset/Perf_collection/Fork_Attack/virus{i}forked.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events = list(df.iloc[0, :])\n",
    "    df = preprocessing (df)\n",
    "    eva_len_list.append(len(df))\n",
    "    eva_df_list.append(df)\n",
    "\n",
    "    \n",
    "df_eva = pd.DataFrame()\n",
    "df_eva = pd.concat(eva_df_list, ignore_index=True)\n",
    "\n",
    "b = [1 for i in range(len(df_eva))]\n",
    "y_eva = np.array(b)\n",
    "\n",
    "y_eva_reduced = [1 for i in range(len(eva_len_list))]\n",
    "\n",
    "print(eva_len_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "\n",
    "df_eva_cp = df_eva[used_features]\n",
    "\n",
    "y_pred = DT_8.predict(df_eva_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "print(f'\\nDT per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "print(f'DT per prog : {accuracy}')\n",
    "\n",
    "for i in range(len(y_eva_reduced)):\n",
    "    if y_eva_reduced[i] != y_pred_reduced[i]:\n",
    "        print(f'Virus {evasive_virus[i]} ({virus_names[i]})... misclassified')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = RF_8.predict(df_eva_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "print(f'\\nRF per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "print(f'RF per prog : {accuracy}')\n",
    "\n",
    "for i in range(len(y_eva_reduced)):\n",
    "    if y_eva_reduced[i] != y_pred_reduced[i]:\n",
    "        print(f'Virus {evasive_virus[i]} ({virus_names[i]})... misclassified')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = GB_8.predict(df_eva_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "print(f'\\nGB per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "print(f'GB per prog : {accuracy}')\n",
    "\n",
    "for i in range(len(y_eva_reduced)):\n",
    "    if y_eva_reduced[i] != y_pred_reduced[i]:\n",
    "        print(f'Virus {evasive_virus[i]} ({virus_names[i]})... misclassified')\n",
    "\n",
    "\n",
    "\n",
    "y_pred = ExT_8.predict(df_eva_cp)\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "print(f'\\nExtra Tree per row : {accuracy}')\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "print(f'Extra Tree per prog : {accuracy}')\n",
    "\n",
    "for i in range(len(y_eva_reduced)):\n",
    "    if y_eva_reduced[i] != y_pred_reduced[i]:\n",
    "        print(f'Virus {evasive_virus[i]} ({virus_names[i]})... misclassified')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "\n",
      "time = 2\n",
      "\n",
      "time = 3\n",
      "\n",
      "time = 4\n",
      "\n",
      "time = 5\n",
      "\n",
      "time = 6\n",
      "\n",
      "time = 7\n",
      "\n",
      "DT_acc_prow: [0.94, 0.89, 0.91, 0.86, 0.92, 0.91, 0.9]\n",
      "DT_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "RF_acc_prow: [0.96, 0.88, 0.88, 0.83, 0.71, 0.88, 0.85]\n",
      "RF_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "GB_acc_prow: [0.93, 0.89, 0.91, 0.86, 0.91, 0.91, 0.89]\n",
      "GB_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "extree_acc_prow: [0.94, 0.82, 0.83, 0.77, 0.72, 0.76, 0.75]\n",
      "extree_acc_pprog: [1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# InstructionsAfterAtomicTasks\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "\n",
    "evasive_virus = [1, 2, 5, 6]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "DT_acc_prow = []\n",
    "DT_acc_pprog = []\n",
    "\n",
    "RF_acc_prow = []\n",
    "RF_acc_pprog = []\n",
    "\n",
    "GB_acc_prow = []\n",
    "GB_acc_pprog = []\n",
    "\n",
    "extree_acc_prow = []\n",
    "extree_acc_pprog = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for time in range(7):\n",
    "\n",
    "    eva_len_list = []\n",
    "    eva_df_list = []\n",
    "    \n",
    "    for v in evasive_virus:\n",
    "        path = f'dataset/Perf_collection/Slowing_Attack/InstructionsAfterAtomicTasks/virus{v}/virus{v}method3run{time+1}.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events = list(df.iloc[0, :])\n",
    "        df = preprocessing (df)\n",
    "        eva_len_list.append(len(df))\n",
    "        eva_df_list.append(df)\n",
    "    \n",
    "    df_eva = pd.DataFrame()\n",
    "    df_eva = pd.concat(eva_df_list, ignore_index=True)\n",
    "    df_eva_cp = df_eva[used_features]\n",
    "\n",
    "    b = [1 for i in range(len(df_eva))]\n",
    "    y_eva = np.array(b)\n",
    "    y_eva_reduced = [1 for i in range(len(eva_len_list))]\n",
    "\n",
    "   \n",
    "\n",
    "    y_pred = DT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    DT_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    DT_acc_pprog.append(accuracy)\n",
    "    \n",
    "    \n",
    "    y_pred = RF_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    RF_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    RF_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    y_pred = GB_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    GB_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    GB_acc_pprog.append(accuracy)\n",
    "\n",
    "    \n",
    "    y_pred = ExT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    extree_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    extree_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'time = {time+1}\\n')\n",
    "            \n",
    "    \n",
    "\n",
    "print(f'DT_acc_prow: {DT_acc_prow}')\n",
    "print(f'DT_acc_pprog: {DT_acc_pprog}')\n",
    "\n",
    "print(f'RF_acc_prow: {RF_acc_prow}')\n",
    "print(f'RF_acc_pprog: {RF_acc_pprog}')\n",
    "\n",
    "print(f'GB_acc_prow: {GB_acc_prow}')\n",
    "print(f'GB_acc_pprog: {GB_acc_pprog}')\n",
    "\n",
    "print(f'extree_acc_prow: {extree_acc_prow}')\n",
    "print(f'extree_acc_pprog: {extree_acc_pprog}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "\n",
      "time = 2\n",
      "\n",
      "time = 3\n",
      "\n",
      "time = 4\n",
      "\n",
      "time = 5\n",
      "\n",
      "time = 6\n",
      "\n",
      "time = 7\n",
      "\n",
      "DT_acc_prow: [0.93, 0.9, 0.88, 0.87, 0.93, 0.93, 0.89]\n",
      "DT_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "RF_acc_prow: [0.94, 0.84, 0.8, 0.76, 0.79, 0.81, 0.81]\n",
      "RF_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "GB_acc_prow: [0.92, 0.9, 0.85, 0.84, 0.89, 0.87, 0.87]\n",
      "GB_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "extree_acc_prow: [0.95, 0.81, 0.8, 0.74, 0.81, 0.81, 0.73]\n",
      "extree_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75]\n"
     ]
    }
   ],
   "source": [
    "# InstructionsBetweenAtomicTasks\n",
    "\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "\n",
    "evasive_virus = [1, 2, 5, 6]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "DT_acc_prow = []\n",
    "DT_acc_pprog = []\n",
    "\n",
    "RF_acc_prow = []\n",
    "RF_acc_pprog = []\n",
    "\n",
    "GB_acc_prow = []\n",
    "GB_acc_pprog = []\n",
    "\n",
    "extree_acc_prow = []\n",
    "extree_acc_pprog = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for time in range(7):\n",
    "\n",
    "    eva_len_list = []\n",
    "    eva_df_list = []\n",
    "    \n",
    "    for v in evasive_virus:\n",
    "        path = f'dataset/Perf_collection/Slowing_Attack/InstructionsBetweenAtomicTasks/virus{v}/virus{v}method4run{time+1}.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events = list(df.iloc[0, :])\n",
    "        df = preprocessing (df)\n",
    "        eva_len_list.append(len(df))\n",
    "        eva_df_list.append(df)\n",
    "    \n",
    "    df_eva = pd.DataFrame()\n",
    "    df_eva = pd.concat(eva_df_list, ignore_index=True)\n",
    "    df_eva_cp = df_eva[used_features]\n",
    "\n",
    "    b = [1 for i in range(len(df_eva))]\n",
    "    y_eva = np.array(b)\n",
    "    y_eva_reduced = [1 for i in range(len(eva_len_list))]\n",
    "\n",
    "   \n",
    "\n",
    "    y_pred = DT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    DT_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    DT_acc_pprog.append(accuracy)\n",
    "    \n",
    "    \n",
    "    y_pred = RF_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    RF_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    RF_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    y_pred = GB_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    GB_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    GB_acc_pprog.append(accuracy)\n",
    "    \n",
    "    y_pred = ExT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    extree_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    extree_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f'time = {time+1}\\n')\n",
    "            \n",
    "    \n",
    "\n",
    "print(f'DT_acc_prow: {DT_acc_prow}')\n",
    "print(f'DT_acc_pprog: {DT_acc_pprog}')\n",
    "\n",
    "print(f'RF_acc_prow: {RF_acc_prow}')\n",
    "print(f'RF_acc_pprog: {RF_acc_pprog}')\n",
    "\n",
    "print(f'GB_acc_prow: {GB_acc_prow}')\n",
    "print(f'GB_acc_pprog: {GB_acc_pprog}')\n",
    "\n",
    "print(f'extree_acc_prow: {extree_acc_prow}')\n",
    "print(f'extree_acc_pprog: {extree_acc_pprog}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "\n",
      "time = 2\n",
      "\n",
      "time = 3\n",
      "\n",
      "time = 4\n",
      "\n",
      "time = 5\n",
      "\n",
      "time = 6\n",
      "\n",
      "time = 7\n",
      "\n",
      "DT_acc_prow: [0.93, 0.85, 0.9, 0.88, 0.89, 0.89, 0.88]\n",
      "DT_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "RF_acc_prow: [0.93, 0.85, 0.92, 0.86, 0.88, 0.92, 0.82]\n",
      "RF_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "GB_acc_prow: [0.91, 0.83, 0.9, 0.87, 0.84, 0.86, 0.75]\n",
      "GB_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "extree_acc_prow: [0.93, 0.81, 0.86, 0.76, 0.76, 0.83, 0.7]\n",
      "extree_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# SleepAfterAtomicTasks\n",
    "\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "\n",
    "evasive_virus = [1, 2, 5, 6]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "DT_acc_prow = []\n",
    "DT_acc_pprog = []\n",
    "\n",
    "RF_acc_prow = []\n",
    "RF_acc_pprog = []\n",
    "\n",
    "GB_acc_prow = []\n",
    "GB_acc_pprog = []\n",
    "\n",
    "extree_acc_prow = []\n",
    "extree_acc_pprog = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for time in range(7):\n",
    "\n",
    "    eva_len_list = []\n",
    "    eva_df_list = []\n",
    "    \n",
    "    for v in evasive_virus:\n",
    "        path = f'dataset/Perf_collection/Slowing_Attack/SleepAfterAtomicTasks/virus{v}/virus{v}method2run{time+1}.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events = list(df.iloc[0, :])\n",
    "        df = preprocessing (df)\n",
    "        eva_len_list.append(len(df))\n",
    "        eva_df_list.append(df)\n",
    "    \n",
    "    df_eva = pd.DataFrame()\n",
    "    df_eva = pd.concat(eva_df_list, ignore_index=True)\n",
    "    df_eva_cp = df_eva[used_features]\n",
    "\n",
    "    b = [1 for i in range(len(df_eva))]\n",
    "    y_eva = np.array(b)\n",
    "    y_eva_reduced = [1 for i in range(len(eva_len_list))]\n",
    "\n",
    "   \n",
    "\n",
    "    y_pred = DT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    DT_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    DT_acc_pprog.append(accuracy)\n",
    "    \n",
    "    \n",
    "    y_pred = RF_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    RF_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    RF_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    y_pred = GB_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    GB_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    GB_acc_pprog.append(accuracy)\n",
    "\n",
    "    y_pred = ExT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    extree_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    extree_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    print(f'time = {time+1}\\n')\n",
    "            \n",
    "    \n",
    "\n",
    "print(f'DT_acc_prow: {DT_acc_prow}')\n",
    "print(f'DT_acc_pprog: {DT_acc_pprog}')\n",
    "\n",
    "print(f'RF_acc_prow: {RF_acc_prow}')\n",
    "print(f'RF_acc_pprog: {RF_acc_pprog}')\n",
    "\n",
    "print(f'GB_acc_prow: {GB_acc_prow}')\n",
    "print(f'GB_acc_pprog: {GB_acc_pprog}')\n",
    "\n",
    "print(f'extree_acc_prow: {extree_acc_prow}')\n",
    "print(f'extree_acc_pprog: {extree_acc_pprog}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "\n",
      "time = 2\n",
      "\n",
      "time = 3\n",
      "\n",
      "time = 4\n",
      "\n",
      "time = 5\n",
      "\n",
      "time = 6\n",
      "\n",
      "time = 7\n",
      "\n",
      "DT_acc_prow: [0.94, 0.87, 0.88, 0.83, 0.85, 0.8, 0.89]\n",
      "DT_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "RF_acc_prow: [0.95, 0.87, 0.86, 0.81, 0.84, 0.82, 0.86]\n",
      "RF_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "GB_acc_prow: [0.92, 0.85, 0.86, 0.8, 0.77, 0.78, 0.86]\n",
      "GB_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "extree_acc_prow: [0.95, 0.84, 0.78, 0.73, 0.71, 0.73, 0.76]\n",
      "extree_acc_pprog: [1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# SleepBetweenAtomicTasks\n",
    "\n",
    "\n",
    "DT_8 = joblib.load(\"model/DT_8.pkl\")\n",
    "RF_8 = joblib.load(\"model/RF_8.pkl\")\n",
    "GB_8 = joblib.load(\"model/GB_8.pkl\")\n",
    "ExT_8 = joblib.load(\"model/ExT_8.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evasive_virus = [1, 2, 5, 6]\n",
    "\n",
    "used_features = [1, 0, 6, 18, 21, 17, 2, 8]\n",
    "\n",
    "DT_acc_prow = []\n",
    "DT_acc_pprog = []\n",
    "\n",
    "RF_acc_prow = []\n",
    "RF_acc_pprog = []\n",
    "\n",
    "GB_acc_prow = []\n",
    "GB_acc_pprog = []\n",
    "\n",
    "extree_acc_prow = []\n",
    "extree_acc_pprog = []\n",
    "\n",
    "\n",
    "for time in range(7):\n",
    "\n",
    "    eva_len_list = []\n",
    "    eva_df_list = []\n",
    "    \n",
    "    for v in evasive_virus:\n",
    "        path = f'dataset/Perf_collection/Slowing_Attack/SleepBetweenAtomicTasks/virus{v}/virus{v}method1run{time+1}.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events = list(df.iloc[0, :])\n",
    "        df = preprocessing (df)\n",
    "        eva_len_list.append(len(df))\n",
    "        eva_df_list.append(df)\n",
    "    \n",
    "    df_eva = pd.DataFrame()\n",
    "    df_eva = pd.concat(eva_df_list, ignore_index=True)\n",
    "    df_eva_cp = df_eva[used_features]\n",
    "\n",
    "    b = [1 for i in range(len(df_eva))]\n",
    "    y_eva = np.array(b)\n",
    "    y_eva_reduced = [1 for i in range(len(eva_len_list))]\n",
    "\n",
    "   \n",
    "\n",
    "    y_pred = DT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    DT_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    DT_acc_pprog.append(accuracy)\n",
    "    \n",
    "    \n",
    "    y_pred = RF_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    RF_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    RF_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    y_pred = GB_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    GB_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    GB_acc_pprog.append(accuracy)\n",
    "\n",
    "    y_pred = ExT_8.predict(df_eva_cp)\n",
    "    y_pred_reduced = find_reduced_prediction(y_pred, eva_df_list)\n",
    "    accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "    extree_acc_prow.append(accuracy)\n",
    "    accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "    extree_acc_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "    print(f'time = {time+1}\\n')\n",
    "            \n",
    "    \n",
    "\n",
    "print(f'DT_acc_prow: {DT_acc_prow}')\n",
    "print(f'DT_acc_pprog: {DT_acc_pprog}')\n",
    "\n",
    "print(f'RF_acc_prow: {RF_acc_prow}')\n",
    "print(f'RF_acc_pprog: {RF_acc_pprog}')\n",
    "\n",
    "print(f'GB_acc_prow: {GB_acc_prow}')\n",
    "print(f'GB_acc_pprog: {GB_acc_pprog}')\n",
    "\n",
    "\n",
    "print(f'extree_acc_prow: {extree_acc_prow}')\n",
    "print(f'extree_acc_pprog: {extree_acc_pprog}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
