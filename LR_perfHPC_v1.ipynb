{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]\n",
      "6 [13000, 13000, 13000, 13000, 13000, 13000]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    " \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import tree, metrics, preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import joblib #save and load model\n",
    " \n",
    "train_size = 0.6\n",
    "validation_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing (df):\n",
    "\n",
    "    #drop 1st row (column title) \n",
    "    for row in range(1):\n",
    "        df = df.drop(row)\n",
    "\n",
    "    #replace NaN = 0 \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    #The pd.to_numberic function will convert all non-parsable strings to 'NaN' \n",
    "    #and the fillna replaces those values with 0\n",
    "    df = df.apply(lambda x: pd.to_numeric(x, errors='coerce')).fillna(0)\n",
    "    df = df.astype(int)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def find_reduced_prediction(y_pred_full, test_df_list):\n",
    "\n",
    "    y_pred_reduced = []\n",
    "\n",
    "    for df_id in range(len(test_df_list)):\n",
    "        start = 0\n",
    "        for i in range(df_id):\n",
    "            start += len(test_df_list[i]) \n",
    "\n",
    "        end = start + len(test_df_list[df_id])\n",
    "        step_size = 1\n",
    "        temp_run_array = y_pred_full[start:end:step_size]\n",
    "\n",
    "        zeros = list(temp_run_array).count(0)\n",
    "        ones = list(temp_run_array).count(1)\n",
    "\n",
    "        if ones > zeros:\n",
    "            y_pred_reduced.append(1)\n",
    "        else:\n",
    "            y_pred_reduced.append(0)\n",
    "\n",
    "    y_pred_reduced = np.array(y_pred_reduced)\n",
    "\n",
    "    return y_pred_reduced \n",
    "\n",
    "\n",
    "\n",
    "def find_misclassification(y_actual, y_predicted, benign, virus):\n",
    "    \n",
    "    misclassified_prog = []\n",
    "    \n",
    "    y_actual = y_test_reduced\n",
    "    y_predicted = y_pred_reduced\n",
    "    for i in range(len(y_actual)):\n",
    "        if y_actual[i] == y_predicted[i]:\n",
    "            print('---')\n",
    "        else:\n",
    "            if y_actual[i] == 0:\n",
    "                print(f'Program {benign[i]}: actual label {y_actual[i]}, predicted as {y_predicted[i]}')\n",
    "            else:\n",
    "                \n",
    "                print(f'Virus Program {virus[i - len(benign)]}: actual label {y_actual[i]}, predicted as {y_predicted[i]}')\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_positive_features(weight):\n",
    "    \n",
    "    positive_weight = []\n",
    "    negative_weight = []\n",
    "    negative_weight_id = []\n",
    "\n",
    "    #argsort gives original index of sorted elements\n",
    "    ascend_id = np.argsort(weight) \n",
    "\n",
    "    descend_id = ascend_id[::-1]\n",
    "\n",
    "    positive_feature_id = list()\n",
    "    count_positive = 0\n",
    "    count_negative = 0\n",
    "    for i in descend_id:\n",
    "        if np.around(weight[i], 6) > 0:\n",
    "            count_positive += 1\n",
    "            positive_feature_id.append(i)\n",
    "            positive_weight.append(round(weight[i], 3))\n",
    "        else:\n",
    "            count_negative += 1\n",
    "            negative_weight.append(round(weight[i], 3))\n",
    "            negative_weight_id.append(i)\n",
    "    return positive_feature_id, positive_weight, negative_weight_id, negative_weight \n",
    "\n",
    "\n",
    "\n",
    "def find_feature_meaning(events, feature_id):\n",
    "    df_preset = pd.read_csv('presets.txt', delimiter=\",\", header=None, low_memory=False)\n",
    "    preset = []\n",
    "    preset__meaning = []\n",
    "    selected_meaning = []\n",
    "\n",
    "    for i in range(0, len(df_preset), 2):\n",
    "        preset.append(df_preset[0][i])\n",
    "\n",
    "    for i in range(1, len(df_preset), 2):\n",
    "        preset__meaning.append(df_preset[0][i])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(feature_id)):\n",
    "        e = events[feature_id[i]]\n",
    "        if e in preset:  \n",
    "            selected_meaning.append(preset__meaning[preset.index(e)])\n",
    "        else:\n",
    "            selected_meaning.append('---')\n",
    "    \n",
    "    return selected_meaning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mibench6 = [1, 2, 3, 4, 5, 6]\n",
    "phoronix7 = [7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "benign = mibench6 \n",
    "\n",
    "virus = [14, 15, 16, 17, 18, 19]\n",
    "\n",
    "train_df_list = []\n",
    "validation_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "\n",
    "train_benign_count = 0\n",
    "validation_benign_count = 0\n",
    "test_benign_count = 0\n",
    "\n",
    "train_malware_count = 0\n",
    "validation_malware_count = 0\n",
    "test_malware_count = 0\n",
    "\n",
    "\n",
    "program_len_list = []\n",
    "for i in benign:\n",
    "    path = f'dataset/Perf_collection/Base_Model_Training_Files/benign/program{i}.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events = list(df.iloc[0, :])\n",
    "    df = preprocessing (df)\n",
    "    \n",
    "    temp_df_list = []\n",
    "    for j in range(6):\n",
    "        temp_df_list.append(df)\n",
    "        \n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp = pd.concat(temp_df_list, ignore_index=True)\n",
    "    \n",
    "    program_len_list.append(len(df_temp))\n",
    "\n",
    "    #df(frac=1) will randomly select rows;\n",
    "    # df_train, df_validate, df_test = np.split(df(frac=1), [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "    #without shuffle\n",
    "#     df_train, df_validate, df_test = np.split(df_temp, [int(train_size*len(df_temp)), int((train_size + validation_size)*len(df_temp))])\n",
    "\n",
    "    train_benign_count += len(df_temp)\n",
    "    validation_benign_count += len(df_temp)\n",
    "    test_benign_count += len(df_temp)\n",
    "\n",
    "    train_df_list.append(df_temp)\n",
    "    validation_df_list.append(df_temp)\n",
    "    test_df_list.append(df_temp)\n",
    "        \n",
    "virus_len_list = []\n",
    "for i in virus:\n",
    "    path = f'dataset/Perf_collection/Base_Model_Training_Files/virus/program{i}.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events = list(df.iloc[0, :])\n",
    "    df = preprocessing (df)\n",
    "    virus_len_list.append(len(df))\n",
    "\n",
    "    #df.sample(frac=1) will randomly select rows;\n",
    "    # df_train, df_validate, df_test = np.split(df(frac=1), [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "    #without shuffle\n",
    "#     df_train, df_validate, df_test = np.split(df, [int(train_size*len(df)), int((train_size + validation_size)*len(df))])\n",
    "\n",
    "\n",
    "    train_malware_count += len(df)\n",
    "    validation_malware_count += len(df)\n",
    "    test_malware_count += len(df)\n",
    "\n",
    "    train_df_list.append(df)\n",
    "    validation_df_list.append(df)\n",
    "    test_df_list.append(df)\n",
    "\n",
    "    \n",
    "    \n",
    "df_train = pd.DataFrame()\n",
    "df_validation = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "df_train = pd.concat(train_df_list, ignore_index=True)\n",
    "df_validation = pd.concat(validation_df_list, ignore_index=True)\n",
    "df_test = pd.concat(test_df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "#generate labels\n",
    "b = [0 if i < train_benign_count else 1 for i in range( train_benign_count + train_malware_count )]\n",
    "y_train = np.array(b)\n",
    "\n",
    "y_train_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_train_reduced.append(1)\n",
    "y_train_reduced = np.array(y_train_reduced)\n",
    "\n",
    "\n",
    "b = [0 if i < validation_benign_count else 1 for i in range( validation_benign_count + validation_malware_count )]\n",
    "y_validation = np.array(b)\n",
    "\n",
    "\n",
    "y_validation_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_validation_reduced.append(1)\n",
    "y_validation_reduced = np.array(y_validation_reduced)\n",
    "\n",
    "\n",
    "b = [0 if i < test_benign_count else 1 for i in range( test_benign_count + test_malware_count )]\n",
    "y_test = np.array(b)\n",
    "\n",
    "y_test_reduced = [0 for i in range(len(benign))]\n",
    "for i in range(len(virus)):\n",
    "    y_test_reduced.append(1)\n",
    "y_test_reduced = np.array(y_test_reduced)\n",
    "\n",
    "print(len(program_len_list), program_len_list)\n",
    "print(len(virus_len_list), virus_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59996</td>\n",
       "      <td>3644</td>\n",
       "      <td>81683</td>\n",
       "      <td>3099</td>\n",
       "      <td>17185</td>\n",
       "      <td>2627581</td>\n",
       "      <td>2322716</td>\n",
       "      <td>2554896</td>\n",
       "      <td>6414</td>\n",
       "      <td>288324</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>274667</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29698</td>\n",
       "      <td>1300</td>\n",
       "      <td>41469</td>\n",
       "      <td>556</td>\n",
       "      <td>6750</td>\n",
       "      <td>2814123</td>\n",
       "      <td>2922207</td>\n",
       "      <td>2810952</td>\n",
       "      <td>6303</td>\n",
       "      <td>41119</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11938</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6946</td>\n",
       "      <td>241</td>\n",
       "      <td>9704</td>\n",
       "      <td>108</td>\n",
       "      <td>7728</td>\n",
       "      <td>2674490</td>\n",
       "      <td>2517595</td>\n",
       "      <td>2672640</td>\n",
       "      <td>0</td>\n",
       "      <td>17103</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8637</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5080</td>\n",
       "      <td>262</td>\n",
       "      <td>8588</td>\n",
       "      <td>124</td>\n",
       "      <td>9778</td>\n",
       "      <td>2677551</td>\n",
       "      <td>2402964</td>\n",
       "      <td>2677656</td>\n",
       "      <td>0</td>\n",
       "      <td>17129</td>\n",
       "      <td>...</td>\n",
       "      <td>1718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2129</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2033</td>\n",
       "      <td>89</td>\n",
       "      <td>3528</td>\n",
       "      <td>88</td>\n",
       "      <td>9689</td>\n",
       "      <td>2625424</td>\n",
       "      <td>2039815</td>\n",
       "      <td>2648856</td>\n",
       "      <td>0</td>\n",
       "      <td>15005</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2948</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155995</td>\n",
       "      <td>12063</td>\n",
       "      <td>57</td>\n",
       "      <td>3527</td>\n",
       "      <td>34</td>\n",
       "      <td>414</td>\n",
       "      <td>68330</td>\n",
       "      <td>13843</td>\n",
       "      <td>68280</td>\n",
       "      <td>33885</td>\n",
       "      <td>103529</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13027</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155996</td>\n",
       "      <td>12859</td>\n",
       "      <td>53</td>\n",
       "      <td>3897</td>\n",
       "      <td>39</td>\n",
       "      <td>414</td>\n",
       "      <td>68480</td>\n",
       "      <td>13844</td>\n",
       "      <td>68376</td>\n",
       "      <td>0</td>\n",
       "      <td>74473</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11199</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155997</td>\n",
       "      <td>11545</td>\n",
       "      <td>52</td>\n",
       "      <td>3399</td>\n",
       "      <td>35</td>\n",
       "      <td>982</td>\n",
       "      <td>109999</td>\n",
       "      <td>21013</td>\n",
       "      <td>109800</td>\n",
       "      <td>0</td>\n",
       "      <td>92500</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10752</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155998</td>\n",
       "      <td>13020</td>\n",
       "      <td>87</td>\n",
       "      <td>4453</td>\n",
       "      <td>69</td>\n",
       "      <td>416</td>\n",
       "      <td>68102</td>\n",
       "      <td>13838</td>\n",
       "      <td>67848</td>\n",
       "      <td>0</td>\n",
       "      <td>127558</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20746</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155999</td>\n",
       "      <td>11966</td>\n",
       "      <td>59</td>\n",
       "      <td>3438</td>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>67704</td>\n",
       "      <td>13437</td>\n",
       "      <td>67368</td>\n",
       "      <td>0</td>\n",
       "      <td>105823</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2     3      4        5        6        7      8   \\\n",
       "0       59996  3644  81683  3099  17185  2627581  2322716  2554896   6414   \n",
       "1       29698  1300  41469   556   6750  2814123  2922207  2810952   6303   \n",
       "2        6946   241   9704   108   7728  2674490  2517595  2672640      0   \n",
       "3        5080   262   8588   124   9778  2677551  2402964  2677656      0   \n",
       "4        2033    89   3528    88   9689  2625424  2039815  2648856      0   \n",
       "...       ...   ...    ...   ...    ...      ...      ...      ...    ...   \n",
       "155995  12063    57   3527    34    414    68330    13843    68280  33885   \n",
       "155996  12859    53   3897    39    414    68480    13844    68376      0   \n",
       "155997  11545    52   3399    35    982   109999    21013   109800      0   \n",
       "155998  13020    87   4453    69    416    68102    13838    67848      0   \n",
       "155999  11966    59   3438    32    421    67704    13437    67368      0   \n",
       "\n",
       "            9   ...    18  19   20      21   22  23  24    25  26  27  \n",
       "0       288324  ...    84   0  320  274667  698   0   0  2609   0   0  \n",
       "1        41119  ...   338   0    0   11938  181   0   0   180   0   0  \n",
       "2        17103  ...   164   0    0    8637  135   0   0   110   0   0  \n",
       "3        17129  ...  1718   0    0    2129   14   0   0    83   0   0  \n",
       "4        15005  ...   510   0   12    2948   27   5   0   217   0  17  \n",
       "...        ...  ...   ...  ..  ...     ...  ...  ..  ..   ...  ..  ..  \n",
       "155995  103529  ...    43   0    0   13027  109   0   0     0   0   0  \n",
       "155996   74473  ...    20   0    0   11199   95   0   0     0   0   0  \n",
       "155997   92500  ...    51   0    0   10752   90   0   0     0   0   0  \n",
       "155998  127558  ...    68   0   12   20746  106   6   0     0   0   0  \n",
       "155999  105823  ...    36   0   16       0  106  11   0     0   0   0  \n",
       "\n",
       "[156000 rows x 28 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59996</td>\n",
       "      <td>3644</td>\n",
       "      <td>81683</td>\n",
       "      <td>3099</td>\n",
       "      <td>17185</td>\n",
       "      <td>2627581</td>\n",
       "      <td>2322716</td>\n",
       "      <td>2554896</td>\n",
       "      <td>6414</td>\n",
       "      <td>288324</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>274667</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29698</td>\n",
       "      <td>1300</td>\n",
       "      <td>41469</td>\n",
       "      <td>556</td>\n",
       "      <td>6750</td>\n",
       "      <td>2814123</td>\n",
       "      <td>2922207</td>\n",
       "      <td>2810952</td>\n",
       "      <td>6303</td>\n",
       "      <td>41119</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11938</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6946</td>\n",
       "      <td>241</td>\n",
       "      <td>9704</td>\n",
       "      <td>108</td>\n",
       "      <td>7728</td>\n",
       "      <td>2674490</td>\n",
       "      <td>2517595</td>\n",
       "      <td>2672640</td>\n",
       "      <td>0</td>\n",
       "      <td>17103</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8637</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5080</td>\n",
       "      <td>262</td>\n",
       "      <td>8588</td>\n",
       "      <td>124</td>\n",
       "      <td>9778</td>\n",
       "      <td>2677551</td>\n",
       "      <td>2402964</td>\n",
       "      <td>2677656</td>\n",
       "      <td>0</td>\n",
       "      <td>17129</td>\n",
       "      <td>...</td>\n",
       "      <td>1718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2129</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2033</td>\n",
       "      <td>89</td>\n",
       "      <td>3528</td>\n",
       "      <td>88</td>\n",
       "      <td>9689</td>\n",
       "      <td>2625424</td>\n",
       "      <td>2039815</td>\n",
       "      <td>2648856</td>\n",
       "      <td>0</td>\n",
       "      <td>15005</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2948</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155995</td>\n",
       "      <td>12063</td>\n",
       "      <td>57</td>\n",
       "      <td>3527</td>\n",
       "      <td>34</td>\n",
       "      <td>414</td>\n",
       "      <td>68330</td>\n",
       "      <td>13843</td>\n",
       "      <td>68280</td>\n",
       "      <td>33885</td>\n",
       "      <td>103529</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13027</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155996</td>\n",
       "      <td>12859</td>\n",
       "      <td>53</td>\n",
       "      <td>3897</td>\n",
       "      <td>39</td>\n",
       "      <td>414</td>\n",
       "      <td>68480</td>\n",
       "      <td>13844</td>\n",
       "      <td>68376</td>\n",
       "      <td>0</td>\n",
       "      <td>74473</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11199</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155997</td>\n",
       "      <td>11545</td>\n",
       "      <td>52</td>\n",
       "      <td>3399</td>\n",
       "      <td>35</td>\n",
       "      <td>982</td>\n",
       "      <td>109999</td>\n",
       "      <td>21013</td>\n",
       "      <td>109800</td>\n",
       "      <td>0</td>\n",
       "      <td>92500</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10752</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155998</td>\n",
       "      <td>13020</td>\n",
       "      <td>87</td>\n",
       "      <td>4453</td>\n",
       "      <td>69</td>\n",
       "      <td>416</td>\n",
       "      <td>68102</td>\n",
       "      <td>13838</td>\n",
       "      <td>67848</td>\n",
       "      <td>0</td>\n",
       "      <td>127558</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20746</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155999</td>\n",
       "      <td>11966</td>\n",
       "      <td>59</td>\n",
       "      <td>3438</td>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>67704</td>\n",
       "      <td>13437</td>\n",
       "      <td>67368</td>\n",
       "      <td>0</td>\n",
       "      <td>105823</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2     3      4        5        6        7      8   \\\n",
       "0       59996  3644  81683  3099  17185  2627581  2322716  2554896   6414   \n",
       "1       29698  1300  41469   556   6750  2814123  2922207  2810952   6303   \n",
       "2        6946   241   9704   108   7728  2674490  2517595  2672640      0   \n",
       "3        5080   262   8588   124   9778  2677551  2402964  2677656      0   \n",
       "4        2033    89   3528    88   9689  2625424  2039815  2648856      0   \n",
       "...       ...   ...    ...   ...    ...      ...      ...      ...    ...   \n",
       "155995  12063    57   3527    34    414    68330    13843    68280  33885   \n",
       "155996  12859    53   3897    39    414    68480    13844    68376      0   \n",
       "155997  11545    52   3399    35    982   109999    21013   109800      0   \n",
       "155998  13020    87   4453    69    416    68102    13838    67848      0   \n",
       "155999  11966    59   3438    32    421    67704    13437    67368      0   \n",
       "\n",
       "            9   ...    18  19   20      21   22  23  24    25  26  27  \n",
       "0       288324  ...    84   0  320  274667  698   0   0  2609   0   0  \n",
       "1        41119  ...   338   0    0   11938  181   0   0   180   0   0  \n",
       "2        17103  ...   164   0    0    8637  135   0   0   110   0   0  \n",
       "3        17129  ...  1718   0    0    2129   14   0   0    83   0   0  \n",
       "4        15005  ...   510   0   12    2948   27   5   0   217   0  17  \n",
       "...        ...  ...   ...  ..  ...     ...  ...  ..  ..   ...  ..  ..  \n",
       "155995  103529  ...    43   0    0   13027  109   0   0     0   0   0  \n",
       "155996   74473  ...    20   0    0   11199   95   0   0     0   0   0  \n",
       "155997   92500  ...    51   0    0   10752   90   0   0     0   0   0  \n",
       "155998  127558  ...    68   0   12   20746  106   6   0     0   0   0  \n",
       "155999  105823  ...    36   0   16       0  106  11   0     0   0   0  \n",
       "\n",
       "[156000 rows x 28 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59996</td>\n",
       "      <td>3644</td>\n",
       "      <td>81683</td>\n",
       "      <td>3099</td>\n",
       "      <td>17185</td>\n",
       "      <td>2627581</td>\n",
       "      <td>2322716</td>\n",
       "      <td>2554896</td>\n",
       "      <td>6414</td>\n",
       "      <td>288324</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>274667</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29698</td>\n",
       "      <td>1300</td>\n",
       "      <td>41469</td>\n",
       "      <td>556</td>\n",
       "      <td>6750</td>\n",
       "      <td>2814123</td>\n",
       "      <td>2922207</td>\n",
       "      <td>2810952</td>\n",
       "      <td>6303</td>\n",
       "      <td>41119</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11938</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6946</td>\n",
       "      <td>241</td>\n",
       "      <td>9704</td>\n",
       "      <td>108</td>\n",
       "      <td>7728</td>\n",
       "      <td>2674490</td>\n",
       "      <td>2517595</td>\n",
       "      <td>2672640</td>\n",
       "      <td>0</td>\n",
       "      <td>17103</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8637</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5080</td>\n",
       "      <td>262</td>\n",
       "      <td>8588</td>\n",
       "      <td>124</td>\n",
       "      <td>9778</td>\n",
       "      <td>2677551</td>\n",
       "      <td>2402964</td>\n",
       "      <td>2677656</td>\n",
       "      <td>0</td>\n",
       "      <td>17129</td>\n",
       "      <td>...</td>\n",
       "      <td>1718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2129</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2033</td>\n",
       "      <td>89</td>\n",
       "      <td>3528</td>\n",
       "      <td>88</td>\n",
       "      <td>9689</td>\n",
       "      <td>2625424</td>\n",
       "      <td>2039815</td>\n",
       "      <td>2648856</td>\n",
       "      <td>0</td>\n",
       "      <td>15005</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2948</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155995</td>\n",
       "      <td>12063</td>\n",
       "      <td>57</td>\n",
       "      <td>3527</td>\n",
       "      <td>34</td>\n",
       "      <td>414</td>\n",
       "      <td>68330</td>\n",
       "      <td>13843</td>\n",
       "      <td>68280</td>\n",
       "      <td>33885</td>\n",
       "      <td>103529</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13027</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155996</td>\n",
       "      <td>12859</td>\n",
       "      <td>53</td>\n",
       "      <td>3897</td>\n",
       "      <td>39</td>\n",
       "      <td>414</td>\n",
       "      <td>68480</td>\n",
       "      <td>13844</td>\n",
       "      <td>68376</td>\n",
       "      <td>0</td>\n",
       "      <td>74473</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11199</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155997</td>\n",
       "      <td>11545</td>\n",
       "      <td>52</td>\n",
       "      <td>3399</td>\n",
       "      <td>35</td>\n",
       "      <td>982</td>\n",
       "      <td>109999</td>\n",
       "      <td>21013</td>\n",
       "      <td>109800</td>\n",
       "      <td>0</td>\n",
       "      <td>92500</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10752</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155998</td>\n",
       "      <td>13020</td>\n",
       "      <td>87</td>\n",
       "      <td>4453</td>\n",
       "      <td>69</td>\n",
       "      <td>416</td>\n",
       "      <td>68102</td>\n",
       "      <td>13838</td>\n",
       "      <td>67848</td>\n",
       "      <td>0</td>\n",
       "      <td>127558</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20746</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155999</td>\n",
       "      <td>11966</td>\n",
       "      <td>59</td>\n",
       "      <td>3438</td>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>67704</td>\n",
       "      <td>13437</td>\n",
       "      <td>67368</td>\n",
       "      <td>0</td>\n",
       "      <td>105823</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2     3      4        5        6        7      8   \\\n",
       "0       59996  3644  81683  3099  17185  2627581  2322716  2554896   6414   \n",
       "1       29698  1300  41469   556   6750  2814123  2922207  2810952   6303   \n",
       "2        6946   241   9704   108   7728  2674490  2517595  2672640      0   \n",
       "3        5080   262   8588   124   9778  2677551  2402964  2677656      0   \n",
       "4        2033    89   3528    88   9689  2625424  2039815  2648856      0   \n",
       "...       ...   ...    ...   ...    ...      ...      ...      ...    ...   \n",
       "155995  12063    57   3527    34    414    68330    13843    68280  33885   \n",
       "155996  12859    53   3897    39    414    68480    13844    68376      0   \n",
       "155997  11545    52   3399    35    982   109999    21013   109800      0   \n",
       "155998  13020    87   4453    69    416    68102    13838    67848      0   \n",
       "155999  11966    59   3438    32    421    67704    13437    67368      0   \n",
       "\n",
       "            9   ...    18  19   20      21   22  23  24    25  26  27  \n",
       "0       288324  ...    84   0  320  274667  698   0   0  2609   0   0  \n",
       "1        41119  ...   338   0    0   11938  181   0   0   180   0   0  \n",
       "2        17103  ...   164   0    0    8637  135   0   0   110   0   0  \n",
       "3        17129  ...  1718   0    0    2129   14   0   0    83   0   0  \n",
       "4        15005  ...   510   0   12    2948   27   5   0   217   0  17  \n",
       "...        ...  ...   ...  ..  ...     ...  ...  ..  ..   ...  ..  ..  \n",
       "155995  103529  ...    43   0    0   13027  109   0   0     0   0   0  \n",
       "155996   74473  ...    20   0    0   11199   95   0   0     0   0   0  \n",
       "155997   92500  ...    51   0    0   10752   90   0   0     0   0   0  \n",
       "155998  127558  ...    68   0   12   20746  106   6   0     0   0   0  \n",
       "155999  105823  ...    36   0   16       0  106  11   0     0   0   0  \n",
       "\n",
       "[156000 rows x 28 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cp = df_train.copy()\n",
    "df_validation_cp = df_validation.copy()\n",
    "df_test_cp = df_test.copy()\n",
    "\n",
    "# df_eva_cp = df_X_eva.copy()\n",
    "\n",
    "#-------PowerTransformer, StandardScaler, RobustScaler, Normalizer, QuantileTransformer, MinMaxScaler\n",
    "#QuantileTransformer(output_distribution='normal'), QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "# scaler = QuantileTransformer(output_distribution='normal')\n",
    "# # scaler = Normalizer()\n",
    "\n",
    "# df_tr  = pd.DataFrame(scaler.fit_transform(df_train_cp))\n",
    "# df_val  = pd.DataFrame(scaler.fit_transform(df_validation_cp))\n",
    "# df_ts  = pd.DataFrame(scaler.fit_transform(df_test_cp))\n",
    "\n",
    "# df_eva  = pd.DataFrame(scaler.fit_transform(df_eva_cp))\n",
    "\n",
    "\n",
    "# used_features = [0, 1, 3, 4, 5, 6, 7, 12]\n",
    "used_features = [0, 1, 3, 4, 5, 6, 7, 16 ]\n",
    "\n",
    "df_train_cp = df_train_cp[used_features]\n",
    "df_validation_cp = df_validation_cp[used_features]\n",
    "df_test_cp = df_test_cp[used_features]\n",
    "\n",
    "\n",
    "# df_tr = df_tr[used_features]\n",
    "# df_val = df_val[used_features]\n",
    "# df_ts = df_ts[used_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59996</td>\n",
       "      <td>3644</td>\n",
       "      <td>3099</td>\n",
       "      <td>17185</td>\n",
       "      <td>2627581</td>\n",
       "      <td>2322716</td>\n",
       "      <td>2554896</td>\n",
       "      <td>3794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29698</td>\n",
       "      <td>1300</td>\n",
       "      <td>556</td>\n",
       "      <td>6750</td>\n",
       "      <td>2814123</td>\n",
       "      <td>2922207</td>\n",
       "      <td>2810952</td>\n",
       "      <td>5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6946</td>\n",
       "      <td>241</td>\n",
       "      <td>108</td>\n",
       "      <td>7728</td>\n",
       "      <td>2674490</td>\n",
       "      <td>2517595</td>\n",
       "      <td>2672640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5080</td>\n",
       "      <td>262</td>\n",
       "      <td>124</td>\n",
       "      <td>9778</td>\n",
       "      <td>2677551</td>\n",
       "      <td>2402964</td>\n",
       "      <td>2677656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2033</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>9689</td>\n",
       "      <td>2625424</td>\n",
       "      <td>2039815</td>\n",
       "      <td>2648856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155995</td>\n",
       "      <td>12063</td>\n",
       "      <td>57</td>\n",
       "      <td>34</td>\n",
       "      <td>414</td>\n",
       "      <td>68330</td>\n",
       "      <td>13843</td>\n",
       "      <td>68280</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155996</td>\n",
       "      <td>12859</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>414</td>\n",
       "      <td>68480</td>\n",
       "      <td>13844</td>\n",
       "      <td>68376</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155997</td>\n",
       "      <td>11545</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>982</td>\n",
       "      <td>109999</td>\n",
       "      <td>21013</td>\n",
       "      <td>109800</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155998</td>\n",
       "      <td>13020</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>416</td>\n",
       "      <td>68102</td>\n",
       "      <td>13838</td>\n",
       "      <td>67848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155999</td>\n",
       "      <td>11966</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>67704</td>\n",
       "      <td>13437</td>\n",
       "      <td>67368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     3      4        5        6        7     16\n",
       "0       59996  3644  3099  17185  2627581  2322716  2554896  3794\n",
       "1       29698  1300   556   6750  2814123  2922207  2810952  5950\n",
       "2        6946   241   108   7728  2674490  2517595  2672640     0\n",
       "3        5080   262   124   9778  2677551  2402964  2677656     0\n",
       "4        2033    89    88   9689  2625424  2039815  2648856     0\n",
       "...       ...   ...   ...    ...      ...      ...      ...   ...\n",
       "155995  12063    57    34    414    68330    13843    68280    11\n",
       "155996  12859    53    39    414    68480    13844    68376     7\n",
       "155997  11545    52    35    982   109999    21013   109800    60\n",
       "155998  13020    87    69    416    68102    13838    67848     0\n",
       "155999  11966    59    32    421    67704    13437    67368     0\n",
       "\n",
       "[156000 rows x 8 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59996</td>\n",
       "      <td>3644</td>\n",
       "      <td>3099</td>\n",
       "      <td>17185</td>\n",
       "      <td>2627581</td>\n",
       "      <td>2322716</td>\n",
       "      <td>2554896</td>\n",
       "      <td>3794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29698</td>\n",
       "      <td>1300</td>\n",
       "      <td>556</td>\n",
       "      <td>6750</td>\n",
       "      <td>2814123</td>\n",
       "      <td>2922207</td>\n",
       "      <td>2810952</td>\n",
       "      <td>5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6946</td>\n",
       "      <td>241</td>\n",
       "      <td>108</td>\n",
       "      <td>7728</td>\n",
       "      <td>2674490</td>\n",
       "      <td>2517595</td>\n",
       "      <td>2672640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5080</td>\n",
       "      <td>262</td>\n",
       "      <td>124</td>\n",
       "      <td>9778</td>\n",
       "      <td>2677551</td>\n",
       "      <td>2402964</td>\n",
       "      <td>2677656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2033</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>9689</td>\n",
       "      <td>2625424</td>\n",
       "      <td>2039815</td>\n",
       "      <td>2648856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155995</td>\n",
       "      <td>12063</td>\n",
       "      <td>57</td>\n",
       "      <td>34</td>\n",
       "      <td>414</td>\n",
       "      <td>68330</td>\n",
       "      <td>13843</td>\n",
       "      <td>68280</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155996</td>\n",
       "      <td>12859</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>414</td>\n",
       "      <td>68480</td>\n",
       "      <td>13844</td>\n",
       "      <td>68376</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155997</td>\n",
       "      <td>11545</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>982</td>\n",
       "      <td>109999</td>\n",
       "      <td>21013</td>\n",
       "      <td>109800</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155998</td>\n",
       "      <td>13020</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>416</td>\n",
       "      <td>68102</td>\n",
       "      <td>13838</td>\n",
       "      <td>67848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155999</td>\n",
       "      <td>11966</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>67704</td>\n",
       "      <td>13437</td>\n",
       "      <td>67368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     3      4        5        6        7     16\n",
       "0       59996  3644  3099  17185  2627581  2322716  2554896  3794\n",
       "1       29698  1300   556   6750  2814123  2922207  2810952  5950\n",
       "2        6946   241   108   7728  2674490  2517595  2672640     0\n",
       "3        5080   262   124   9778  2677551  2402964  2677656     0\n",
       "4        2033    89    88   9689  2625424  2039815  2648856     0\n",
       "...       ...   ...   ...    ...      ...      ...      ...   ...\n",
       "155995  12063    57    34    414    68330    13843    68280    11\n",
       "155996  12859    53    39    414    68480    13844    68376     7\n",
       "155997  11545    52    35    982   109999    21013   109800    60\n",
       "155998  13020    87    69    416    68102    13838    67848     0\n",
       "155999  11966    59    32    421    67704    13437    67368     0\n",
       "\n",
       "[156000 rows x 8 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used_features [0, 1, 3, 4, 5, 6, 7, 16]\n",
      "acc_prow: [0.71]\n",
      "acc_pprog [0.79]\n"
     ]
    }
   ],
   "source": [
    "# #-----------------------------------------------------------------\n",
    "\n",
    "# base LR on original data\n",
    "\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(df_tr, y_train)\n",
    "# feat_importances = pd.Series(model.feature_importances_, index = df_tr.columns)\n",
    "\n",
    "acc_prow = []\n",
    "acc_pprog = []\n",
    "\n",
    "\n",
    "print('used_features', used_features)\n",
    "\n",
    "lr_model_perf = LogisticRegression(solver='liblinear', max_iter=2000)\n",
    "lr_model_perf.fit(df_train_cp, y_train)\n",
    "\n",
    "joblib.dump(lr_model_perf, \"model/lr_model_perf.pkl\")\n",
    "lr_model_perf = joblib.load(\"model/lr_model_perf.pkl\")\n",
    "\n",
    "probs_y = lr_model_perf.predict_proba(df_validation_cp)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_validation, probs_y)\n",
    "optimal_th = round(thresholds[np.argmax(tpr - fpr)], 2)\n",
    "\n",
    "probs_y = lr_model_perf.predict_proba(df_test_cp)[:,1]\n",
    "y_pred = [1 if i > optimal_th else 0 for i in probs_y]\n",
    "\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, test_df_list)\n",
    "\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "acc_prow.append(accuracy)\n",
    "\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "acc_pprog.append(accuracy)\n",
    "\n",
    "print('acc_prow:', acc_prow)\n",
    "print('acc_pprog', acc_pprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Branch-instructions\n",
      "1 Branch-misses\n",
      "3 Cache-misses\n",
      "4 Cache-references\n",
      "5 CPU-cycles\n",
      "6 Instructions\n",
      "7 Ref-cycles\n",
      "16 branch-load-misses\n"
     ]
    }
   ],
   "source": [
    "for i in used_features:\n",
    "    print(i, events[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base LR on \"TEST DATA [35] + 100\": accuracy per row : [0.48]\n",
      "base LR on \"TEST DATA [35] + 100\": accuracy per prog : [0.48]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add 100 to -ve features\n",
    "# base LR\n",
    "\n",
    "\n",
    "weight = lr_model_all_features.coef_[0]\n",
    "positive_feature_id, positive_weight, negative_feature_id, negative_weight = find_positive_features(weight)\n",
    "\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "\n",
    "df_ts_cp[35].values[:] =  df_ts_cp[35].values[:] + 100 \n",
    "\n",
    "\n",
    "y_pred = lr_model_all_features.predict(df_ts_cp)\n",
    "\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "lr_acc_ts_prow.append(accuracy)\n",
    "\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(f'base LR on \"TEST DATA [35] + 100\": accuracy per row : {lr_acc_ts_prow}\\n')\n",
    "print(f'base LR on \"TEST DATA [35] + 100\": accuracy per prog : {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monotonic LR on \"ORIGINAL test data\": accuracy per row: [0.67]\n",
      "Monotonic LR on \"ORIGINAL test data\": accuracy per prog: [0.8]\n",
      "\n",
      "Monotonic LR on \"EVASIVE [fork method]\": accuracy per row: [1.0]\n",
      "Monotonic LR on \"EVASIVE [fork method]\": accuracy per prog: [1.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shohidul/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py:651: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add 100 to feature 35\n",
    "# monotonic LR\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "monotonic_feature = [6, 19, 50, 22]\n",
    "\n",
    "\n",
    "# df_ts_cp[35].values[:] =  df_ts_cp[35].values[:] + 100\n",
    "\n",
    "\n",
    "# df_ts  = pd.DataFrame(scaler.fit_transform(df_ts_cp))\n",
    "\n",
    "\n",
    "# for col in df_ts.columns:\n",
    "#         if col not in monotonic_feature:\n",
    "#             df_ts[col].values[:] = 0\n",
    "    \n",
    "\n",
    "\n",
    "# # probs_y = lr_model_all_features.predict_proba(df_val)[:,1]\n",
    "# # print(f'LR validation optimal threshold: {optimal_th}\\n')\n",
    "\n",
    "    \n",
    "# probs_y = lr_model_all_features.predict_proba(df_ts)[:,1]\n",
    "\n",
    "# y_pred = [1 if i > 0.99 else 0 for i in probs_y]\n",
    "# y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "# accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "# lr_acc_ts_prow.append(accuracy)\n",
    "# accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "# lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "# print(f'Monotonic LR on \"TEST DATA [35] + 100\": accuracy per row: {lr_acc_ts_prow}')\n",
    "# print(f'Monotonic LR on \"TEST DATA [35] + 100\": accuracy per prog: {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "\n",
    "for col in df_ts.columns:\n",
    "        if col not in monotonic_feature:\n",
    "            df_ts[col].values[:] = 0\n",
    "\n",
    "\n",
    "probs_y = lr_model_all_features.predict_proba(df_ts)[:,1]\n",
    "\n",
    "y_pred = [1 if i > 0.99 else 0 for i in probs_y]\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "lr_acc_ts_prow.append(accuracy)\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "print(f'Monotonic LR on \"ORIGINAL test data\": accuracy per row: {lr_acc_ts_prow}')\n",
    "print(f'Monotonic LR on \"ORIGINAL test data\": accuracy per prog: {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "\n",
    "\n",
    "for col in df_eva_cp.columns:\n",
    "        if col not in monotonic_feature:\n",
    "            df_eva_cp[col].values[:] = 0\n",
    "\n",
    "\n",
    "probs_y = lr_model_all_features.predict_proba(df_eva_cp)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_eva, probs_y)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "y_pred = [1 if i > 0.99 else 0 for i in probs_y]\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "lr_acc_ts_prow.append(accuracy)\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "print(f'Monotonic LR on \"EVASIVE [fork method]\": accuracy per row: {lr_acc_ts_prow}')\n",
    "print(f'Monotonic LR on \"EVASIVE [fork method]\": accuracy per prog: {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "\n",
    "from pylab import text\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr, tpr, label = f'AUC = {round(accuracy, 2)}', color = 'blue')\n",
    "\n",
    "text(0.4, 0.33, 'Random Classification', fontsize=12, rotation = 33)\n",
    "\n",
    "plt.xlim([0.0, 1])\n",
    "plt.ylim([0.0, 1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', color = 'gray', linestyle = '--', marker = 'o')\n",
    "plt.xlabel('False Positives Rate')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('ROC of Monotonic LR')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('figure/ROC_mono_LR.pdf', bbox_inches='tight')\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importance LR on \"TEST DATA + 100\": accuracy per row : [0.52]\n",
      "feature importance LR on \"TEST DATA + 100\": accuracy per prog: [0.52]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add 100 to feature 35\n",
    "# feature importance\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "important_feature = [20, 22, 0, 35]\n",
    "\n",
    "\n",
    "df_ts_cp[20].values[:] =  df_ts_cp[20].values[:] + 100\n",
    "df_ts_cp[35].values[:] =  df_ts_cp[35].values[:] + 100\n",
    "\n",
    "\n",
    "# df_ts = scaler.fit_transform(df_ts_cp)\n",
    "# df_ts  = pd.DataFrame(df_ts)\n",
    "\n",
    "df_X_test_reduced_feature = df_ts_cp[important_feature]\n",
    "\n",
    "probs_y = lr_reduced.predict_proba(df_X_test_reduced_feature)[:,1]\n",
    "y_pred = [1 if i > optimal_th else 0 for i in probs_y]\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "lr_acc_ts_prow.append(accuracy)\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(f'feature importance LR on \"TEST DATA + 100\": accuracy per row : {lr_acc_ts_prow}')\n",
    "print(f'feature importance LR on \"TEST DATA + 100\": accuracy per prog: {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_used: [20, 22, 0, 35]\n",
      "LR validation optimal threshold: 0.5\n",
      "\n",
      "feature importance LR on original test data: accuracy per row : [0.73]\n",
      "feature importance LR on original test data: accuracy per prog : [0.96]\n",
      "\n",
      "feature importance LR on EVASIVE test data [fork method]: accuracy per row : [0.5]\n",
      "feature importance LR on EVASIVE test data [fork method]: accuracy per prog : [0.53]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR feature importance\n",
    "\n",
    "lr_acc_ts_prow = []\n",
    "lr_acc_ts_pprog = []\n",
    "\n",
    "lr_acc_eva_prow = []\n",
    "lr_acc_eva_pprog = []\n",
    "\n",
    "\n",
    "important_feature = [20, 22, 0, 35]\n",
    "\n",
    "\n",
    "print(f'feature_used: {important_feature}')\n",
    "\n",
    "df_X_train_reduced_feature = df_tr[important_feature]\n",
    "df_X_validate_reduced_feature = df_val[important_feature]\n",
    "df_X_test_reduced_feature = df_ts[important_feature]\n",
    "df_eva_reduced_feature = df_eva[important_feature]\n",
    "\n",
    "\n",
    "lr_reduced = joblib.load(\"lr_reduced.pkl\")\n",
    "\n",
    "\n",
    "probs_y = lr_reduced.predict_proba(df_X_validate_reduced_feature)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_validation, probs_y)\n",
    "optimal_th = round(thresholds[np.argmax(tpr - fpr)], 2)\n",
    "\n",
    "print(f'LR validation optimal threshold: {optimal_th}\\n')\n",
    "\n",
    "probs_y = lr_reduced.predict_proba(df_X_test_reduced_feature)[:,1]\n",
    "y_pred = [1 if i > optimal_th else 0 for i in probs_y]\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "accuracy  = round(np.mean(y_pred == y_test), 2)\n",
    "lr_acc_ts_prow.append(accuracy)\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_test_reduced), 2)\n",
    "lr_acc_ts_pprog.append(accuracy)\n",
    "\n",
    "probs_y = lr_reduced.predict_proba(df_eva_reduced_feature)[:,1]\n",
    "y_pred = [1 if i > optimal_th else 0 for i in probs_y]\n",
    "y_pred_reduced = find_reduced_prediction(y_pred, run_length)\n",
    "accuracy  = round(np.mean(y_pred == y_eva), 2)\n",
    "lr_acc_eva_prow.append(accuracy)\n",
    "accuracy  = round(np.mean(y_pred_reduced == y_eva_reduced), 2)\n",
    "lr_acc_eva_pprog.append(accuracy)     \n",
    "\n",
    "\n",
    "print(f'feature importance LR on original test data: accuracy per row : {lr_acc_ts_prow}')\n",
    "print(f'feature importance LR on original test data: accuracy per prog : {lr_acc_ts_pprog}\\n')\n",
    "\n",
    "print(f'feature importance LR on EVASIVE test data [fork method]: accuracy per row : {lr_acc_eva_prow}')\n",
    "print(f'feature importance LR on EVASIVE test data [fork method]: accuracy per prog : {lr_acc_eva_pprog}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading evasive dataset\n",
    "temp = []\n",
    "for v in range(7):\n",
    "\n",
    "    if v == 2:\n",
    "        continue\n",
    "    \n",
    "    path = f'dataset/new_data/evasive/virus{v+1}withaddedhpcs.csv'\n",
    "    df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "    events_eva = df.iloc[0, :]\n",
    "    df = preprocessing (df)\n",
    "    temp.append(df)\n",
    "\n",
    "run_length_eva = len(df)\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp =  pd.concat(temp, ignore_index=True)\n",
    "\n",
    "df_X_eva = df_temp.copy()\n",
    "\n",
    "#generate evasive labels\n",
    "y_eva = np.array([1 for i in range(len(df_X_eva))])\n",
    "y_eva_reduced = np.array([1 for i in range(int(len(y_eva)/run_length_eva))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(2):\n",
    "    \n",
    "    if i == 2:\n",
    "        continue\n",
    "    \n",
    "    for j in range(1):\n",
    "        path = f'dataset/new_data/1000us/Virus{i+1}/Virus{i+1}run{j+1}.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events = df.iloc[0, :]\n",
    "        df = preprocessing (df)\n",
    "        temp.append(df)\n",
    "\n",
    "df_before = pd.DataFrame()\n",
    "df_before =  pd.concat(temp, ignore_index=True)\n",
    "\n",
    "\n",
    "temp = []\n",
    "for v in range(1):\n",
    "\n",
    "    if v == 2:\n",
    "        continue\n",
    "        \n",
    "    for j in range(2):\n",
    "#         path = f'dataset/new_data/evasive/Flushing_array_and_reload_method-5/all_hpc/Virus{v+1}/Virus{v+1}run{j+1}.csv'\n",
    "        path = f'dataset/new_data/evasive/virus{j+1}withaddedhpcs.csv'\n",
    "        df = pd.read_csv(path, delimiter=\",\", header=None, low_memory=False)\n",
    "        events_eva = df.iloc[0, :]\n",
    "        df = preprocessing (df)\n",
    "        temp.append(df)\n",
    "\n",
    "\n",
    "df_after = pd.DataFrame()\n",
    "df_after =  pd.concat(temp, ignore_index=True)\n",
    "\n",
    "len(df_before)\n",
    "\n",
    "len(df_after)\n",
    "\n",
    "feature = [6, 19, 50, 22, 35]\n",
    "events = list(events)\n",
    "\n",
    "\n",
    "x = [i+1 for i in range(len(df_before)) ]\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "for col in feature:\n",
    "    plt.figure()\n",
    "\n",
    "    y1 = df_before[col]\n",
    "    y2 = df_after[col]\n",
    "    \n",
    "#     y1 = pd.DataFrame(df_ts_cp[col].values[0:len(df_before)])\n",
    "#     y2 = y1 \n",
    "\n",
    "    plt.plot(x,y1, label = 'before fork attack')\n",
    "    plt.plot(x,y2, label = 'after fork attack')\n",
    "\n",
    "    plt.xlabel('samples')\n",
    "    plt.ylabel('count')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, - 0.15), frameon=False, ncol = 2)\n",
    "    \n",
    "    meaning = find_feature_meaning(events, [col])\n",
    "    \n",
    "    plt.title(f'run={j+1}  {col}: {events[col]}: {meaning[0]}')\n",
    "    \n",
    "    filename = f'figure/feature{col}_run{j+1}.pdf'\n",
    "    \n",
    "    plt.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
